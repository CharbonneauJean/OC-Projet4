{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c9b4cbb",
   "metadata": {},
   "source": [
    "# Projet 4 - Segmentation des clients d'un site e-commerce\n",
    "\n",
    "## Analyse exploratoire et création d'un dataset clean\n",
    "\n",
    "Le but de ce notebook est d'analyser le jeu de données initial et de le traiter afin de produire un dataset \"clean\", exporté en csv, qui sera la base du travail de machine learning consécutif.\n",
    "\n",
    "### Table des matières\n",
    "1. [Importation et préparation des données](#1-importation-et-préparation-des-données)\n",
    "2. [Analyse des données manquantes](#2-analyse-des-données-manquantes)\n",
    "3. [Analyse des variables numériques](#3-analyse-des-variables-numériques)\n",
    "4. [Analyse des variables catégorielles](#4-analyse-des-variables-catégorielles)\n",
    "5. [Analyse des corrélations](#5-analyse-des-corrélations)\n",
    "6. [Feature Engineering](#6-feature-engineering)\n",
    "6.5. [Analyse RFM préliminaire](#65-analyse-rfm-préliminaire)\n",
    "7. [Traitement des outliers](#7-traitement-des-outliers)\n",
    "8. [Préparation du dataset final](#8-préparation-du-dataset-final)\n",
    "9. [Conclusion et prochaines étapes](#9-conclusion-et-prochaines-étapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebe5960",
   "metadata": {},
   "source": [
    "### Imports et paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11d73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # Désactive l'avertissement SettingWithCopyWarning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from MLUtils import DataAnalysis, DataEngineering\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Pour une meilleure lisibilité des graphiques\n",
    "plt.style.use('ggplot')  # Utilisation d'un style valide de matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Configuration de seaborn pour une meilleure esthétique\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92dd540",
   "metadata": {},
   "source": [
    "## 1. Importation et préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23934358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du jeu de données\n",
    "df = pd.read_csv('data/customer_segments3_202409201627.csv')\n",
    "print(f\"Le jeu initial de données contient {df.shape[0]} observations réparties en {df.shape[1]} colonnes/variables.\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e470429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Feature Engineering\n",
    "\n",
    "# 1. Calcul du ratio de dépense moyenne par commande\n",
    "df['avg_spent_per_order'] = df['total_spent'] / df['total_orders']\n",
    "\n",
    "# 2. Calcul de l'intervalle moyen entre commandes (en jours)\n",
    "# Pour les clients ayant plus d'une commande, on estime l'intervalle moyen en divisant\n",
    "# le nombre de jours depuis la dernière commande par (total_orders - 1).\n",
    "# Pour les clients avec une seule commande, on utilise le nombre de jours depuis la dernière commande\n",
    "df['avg_days_between_orders'] = df.apply(\n",
    "    lambda row: row['days_since_last_order'] / (row['total_orders'] - 1) if row['total_orders'] > 1 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "df['avg_days_between_orders'].fillna(df['days_since_last_order'], inplace=True)\n",
    "\n",
    "# 3. Calcul d'un score de fidélité combiné\n",
    "# Un score plus élevé indique un client dépensant beaucoup par commande et passant peu de temps entre ses commandes\n",
    "df['loyalty_score'] = df['avg_spent_per_order'] / (df['avg_days_between_orders'] + 1)\n",
    "\n",
    "# 4. Créer une variable binaire pour le type de paiement (1 pour carte de crédit, 0 pour les autres)\n",
    "df['is_credit_card'] = df['last_payment_type'].apply(lambda x: 1 if x == 'credit_card' else 0)\n",
    "\n",
    "# 5. Créer une variable pour la récence (plus la valeur est faible, plus le client est récent)\n",
    "df['recency_score'] = df['days_since_last_order'].rank(pct=True)\n",
    "\n",
    "# 6. Créer une variable pour la fréquence (inversée par rapport à avg_days_between_orders)\n",
    "df['frequency_score'] = 1 / (df['avg_days_between_orders'] + 1)\n",
    "\n",
    "# Affichage des nouvelles variables\n",
    "print(\"Aperçu des variables créées par feature engineering:\")\n",
    "display(df[['avg_spent_per_order', 'avg_days_between_orders', 'loyalty_score', \n",
    "         'is_credit_card', 'recency_score', 'frequency_score']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09173a9d",
   "metadata": {},
   "source": [
    "## 6.5 Analyse RFM préliminaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e33363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 Analyse RFM préliminaire\n",
    "print(\"### Analyse RFM (Récence, Fréquence, Montant) ###\")\n",
    "\n",
    "# Création des quintiles pour chaque dimension RFM\n",
    "# Récence (une valeur plus faible = meilleur)\n",
    "df['R_score'] = pd.qcut(df['days_since_last_order'], q=5, labels=[5, 4, 3, 2, 1])\n",
    "\n",
    "# Fréquence (via notre variable frequency_score - une valeur plus élevée = meilleur)\n",
    "df['F_score'] = pd.qcut(df['frequency_score'], q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Montant (avg_spent_per_order - une valeur plus élevée = meilleur)\n",
    "df['M_score'] = pd.qcut(df['avg_spent_per_order'], q=5, labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "# Combinaison des scores RFM\n",
    "df['RFM_score'] = df['R_score'].astype(str) + df['F_score'].astype(str) + df['M_score'].astype(str)\n",
    "\n",
    "# Création de segments clients simplifiés\n",
    "def segment_client(rfm_score):\n",
    "    r = int(rfm_score[0])\n",
    "    f = int(rfm_score[1])\n",
    "    m = int(rfm_score[2])\n",
    "    \n",
    "    if r >= 4 and f >= 4 and m >= 4:\n",
    "        return 'Champions'\n",
    "    elif r >= 3 and f >= 3 and m >= 3:\n",
    "        return 'Clients loyaux'\n",
    "    elif r >= 3 and f >= 1 and m >= 2:\n",
    "        return 'Clients potentiels'\n",
    "    elif r <= 2 and f <= 2 and m <= 2:\n",
    "        return 'Clients à risque'\n",
    "    elif r == 1 and f == 1 and m == 1:\n",
    "        return 'Clients perdus'\n",
    "    else:\n",
    "        return 'Autres'\n",
    "\n",
    "df['segment_RFM'] = df['RFM_score'].apply(segment_client)\n",
    "\n",
    "# Affichage des segments\n",
    "segment_counts = df['segment_RFM'].value_counts()\n",
    "print(\"\\nDistribution des segments RFM:\")\n",
    "print(segment_counts)\n",
    "\n",
    "# Visualisation\n",
    "plt.figure(figsize=(10, 6))\n",
    "segment_counts.plot(kind='bar', color=sns.color_palette(\"viridis\", len(segment_counts)))\n",
    "plt.title('Distribution des segments clients selon analyse RFM')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Nombre de clients')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyse des caractéristiques moyennes par segment\n",
    "segment_profile = df.groupby('segment_RFM').agg({\n",
    "    'days_since_last_order': 'mean',\n",
    "    'frequency_score': 'mean',\n",
    "    'avg_spent_per_order': 'mean',\n",
    "    'loyalty_score': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nProfil moyen des segments:\")\n",
    "display(segment_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659adf2",
   "metadata": {},
   "source": [
    "## 2. Analyse des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8676231",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_percentages = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"Pourcentage de valeurs manquantes par colonne:\")\n",
    "display(missing_percentages[missing_percentages > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05431717",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataAnalysis.show_columns_population(df, 'matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4339de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e32cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime la colonne \"last_order_date\" car elle ne nous sera pas utile, nous avons déjà la colonne \"days_since_last_order\"\n",
    "df = df.drop(columns=['last_order_date'])\n",
    "\n",
    "# On supprime les observations avec des valeurs manquantes\n",
    "df = df.dropna()\n",
    "print(f\"Après suppression des valeurs manquantes, nous avons {df.shape[0]} observations utilisables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eedef6",
   "metadata": {},
   "source": [
    "## 3. Analyse des variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba79f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes numériques\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "print(\"Colonnes numériques :\")\n",
    "print(numeric_columns)\n",
    "\n",
    "# Statistiques descriptives\n",
    "df[numeric_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Nombre total de graphiques à tracer\n",
    "num_plots = len(numeric_columns)\n",
    "# Définir le nombre de colonnes souhaité, par exemple 3\n",
    "num_cols = 3\n",
    "# Calculer le nombre de lignes nécessaires\n",
    "num_rows = math.ceil(num_plots / num_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
    "axes = axes.flatten()  # Mettre tous les axes dans un tableau 1D\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution de {col}')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "# Supprimer les axes inutilisés\n",
    "for ax in axes[num_plots:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b36fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, column):\n",
    "\t# Calcul des quartiles et de l'IQR\n",
    "\tQ1 = df[column].quantile(0.25)\n",
    "\tQ3 = df[column].quantile(0.75)\n",
    "\tIQR = Q3 - Q1\n",
    "\n",
    "\t# Définition des bornes\n",
    "\tlower_bound = Q1 - 1.5 * IQR\n",
    "\tupper_bound = Q3 + 1.5 * IQR\n",
    "\t\n",
    "\t# Filtrer le DataFrame\n",
    "\tinitial_count = len(df)\n",
    "\tfiltered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\tremoved_count = initial_count - len(filtered_df)\n",
    "\t\n",
    "\t# Affichage des informations\n",
    "\tprint(f\"Colonne '{column}' : {removed_count} outliers supprimés.\")\n",
    "\tprint(f\"Nouvelles limites : lower_bound = {lower_bound:.2f}, upper_bound = {upper_bound:.2f}\")\n",
    "\t\n",
    "\treturn filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afd0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Traitement des outliers\n",
    "# Fonction pour identifier et supprimer les outliers avec la méthode IQR\n",
    "def remove_outliers(df, column):\n",
    "    # Calcul des quartiles et de l'IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Définition des bornes\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filtrer le DataFrame\n",
    "    initial_count = len(df)\n",
    "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    removed_count = initial_count - len(filtered_df)\n",
    "    \n",
    "    # Affichage des informations\n",
    "    print(f\"Colonne '{column}' : {removed_count} outliers supprimés ({removed_count/initial_count*100:.2f}%).\")\n",
    "    print(f\"Nouvelles limites : lower_bound = {lower_bound:.2f}, upper_bound = {upper_bound:.2f}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Appliquer la suppression des outliers aux colonnes numériques pertinentes\n",
    "print(\"Suppression des outliers sur les variables clés...\")\n",
    "df = remove_outliers(df, 'avg_delivery_time_days')\n",
    "df = remove_outliers(df, 'last_payment_installments')\n",
    "df = remove_outliers(df, 'avg_spent_per_order')\n",
    "df = remove_outliers(df, 'loyalty_score')\n",
    "\n",
    "print(f\"\\nAprès suppression des outliers, nous avons {df.shape[0]} observations utilisables.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7300a41d",
   "metadata": {},
   "source": [
    "# Analyse de la colonne 'total_orders'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ab1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trouver les valeurs différentes et le count pour chacun d'elle pour cette colonne\n",
    "#df['total_orders'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41377061",
   "metadata": {},
   "source": [
    "Nous constatons que la plupart des clients ont fait une seule commande. Nous allons donc classer les clients en deux buckets : \n",
    "- ceux qui ont fait une seule commande\n",
    "- ceux qui ont fait plus d'une commande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une colonne \"more_than_one_order\" qui sera à 1 si le client a passé plus d'une commande, 0 sinon\n",
    "df['more_than_one_order'] = df['total_orders'].apply(lambda x: 0 if x == 1 else 1)\n",
    "\n",
    "# On peut alors drop la colonne \"total_orders\"\n",
    "df = df.drop(columns=['total_orders'])\n",
    "\n",
    "# Enlever 'total_order' de numeric_columns\n",
    "numeric_columns = numeric_columns.drop('total_orders')\n",
    "\n",
    "# Ajouter 'more_than_one_order' à numeric_columns\n",
    "numeric_columns = pd.Index(['more_than_one_order']).append(numeric_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcec82b",
   "metadata": {},
   "source": [
    "# Analyse de la colonne 'avg_delivery_time_days'\n",
    "\n",
    "On constate sur le graphique de répartition de cette colonne que la courbe est bien lisse pour les valeurs inférieures à 70 jours. Nous allons donc éliminer les valeurs supérieures à 70 jours qui sont des outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef4c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les lignes avec des valeurs supérieures à 70 pour la colonne 'avg_delivery_time_days'\n",
    "# df = df[df['avg_delivery_time_days'] <= 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bd979",
   "metadata": {},
   "source": [
    "# Analyse de la colonne 'days_since_last_order'\n",
    "\n",
    "On constate sur le graphique de répartition de cette colonne que la courbe est bien lisse pour les valeurs inférieures à 650 jours. Nous allons donc éliminer les valeurs supérieures à 650 jours qui sont des outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e8d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les lignes avec des valeurs supérieures à 70 pour la colonne 'days_since_last_order'\n",
    "# df = df[df['days_since_last_order'] <= 650]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910ebe0b",
   "metadata": {},
   "source": [
    "# Analyse de la colonne 'total_spent'\n",
    "\n",
    "On constate sur le graphique de répartition de cette colonne que la courbe est bien lisse pour les valeurs inférieures à 1000. Nous allons donc éliminer les valeurs supérieures à 1000 qui sont des outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les lignes avec des valeurs supérieures à 1000 pour la colonne 'total_spent'\n",
    "# df = df[df['total_spent'] <= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58836e",
   "metadata": {},
   "source": [
    "# Voyons si nos graphes sont plus précis et exploitable maintenant que les outliers ont été enlevés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac3ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Nombre total de graphiques à tracer\n",
    "num_plots = len(numeric_columns)\n",
    "# Définir le nombre de colonnes souhaité, par exemple 3\n",
    "num_cols = 3\n",
    "# Calculer le nombre de lignes nécessaires\n",
    "num_rows = math.ceil(num_plots / num_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
    "axes = axes.flatten()  # Mettre tous les axes dans un tableau 1D\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution de {col}')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "# Supprimer les axes inutilisés\n",
    "for ax in axes[num_plots:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show number of lines remaining after removing outliers\n",
    "print(f\"Après suppression des outliers, nous avons {df.shape[0]} observations utilisables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c75543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a4a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop avg_delivery_delay_days and max_delivery_delay_days\n",
    "# df = df.drop(columns=['avg_delivery_delay_days', 'max_delivery_delay_days'])\n",
    "\n",
    "# # remove from numeric_columns\n",
    "# numeric_columns = numeric_columns.drop(['avg_delivery_delay_days', 'max_delivery_delay_days'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Nombre total de graphiques à tracer\n",
    "num_plots = len(numeric_columns)\n",
    "# Définir le nombre de colonnes souhaité, par exemple 3\n",
    "num_cols = 3\n",
    "# Calculer le nombre de lignes nécessaires\n",
    "num_rows = math.ceil(num_plots / num_cols)\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
    "axes = axes.flatten()  # Mettre tous les axes dans un tableau 1D\n",
    "\n",
    "for idx, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[idx])\n",
    "    axes[idx].set_title(f'Distribution de {col}')\n",
    "    axes[idx].set_xlabel('')\n",
    "\n",
    "# Supprimer les axes inutilisés\n",
    "for ax in axes[num_plots:]:\n",
    "    fig.delaxes(ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7fc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Les colonnes max_delivery_delay_days et avg_delivery_delay_days contiennent des valeurs identiques. Nous le vérifions, et si c'est le cas, supprimons une des colonnes.\n",
    "# print(\"Les colonnes max_delivery_delay_days et avg_delivery_delay_days contiennent-elles les mêmes valeurs ?\")\n",
    "# sameValues = (df['max_delivery_delay_days'] == df['avg_delivery_delay_days']).all()\n",
    "\n",
    "# # quelles sont les valeurs différentes entre les deux colonnes ?\n",
    "# if not sameValues:\n",
    "#     print(\"Les colonnes max_delivery_delay_days et avg_delivery_delay_days ne contiennent pas les mêmes valeurs.\")\n",
    "#     print(\"Valeurs différentes entre les deux colonnes :\")\n",
    "#     print(df.loc[df['max_delivery_delay_days'] != df['avg_delivery_delay_days'], ['max_delivery_delay_days', 'avg_delivery_delay_days']])\n",
    "\n",
    "# # Suppression de la colonne avg_delivery_delay_days\n",
    "# if sameValues:\n",
    "#     print(\"Les colonnes max_delivery_delay_days et avg_delivery_delay_days contiennent les mêmes valeurs. Nous allons supprimer la colonne avg_delivery delay_days.\")\n",
    "#     df = df.drop(columns=['avg_delivery_delay_days'])\n",
    "#     numeric_columns = numeric_columns.drop('avg_delivery_delay_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57453e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il n'y a que 188 cas où la valeur est différente. Nous supprimons la colonne avg_delivery_delay_days.\n",
    "# df = df.drop(columns=['avg_delivery_delay_days'])\n",
    "\n",
    "# on enlève avg_delivery_delay_days de numeric_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858eb34",
   "metadata": {},
   "source": [
    "### Analyse des outliers\n",
    "\n",
    "Nous pouvons observer que certaines variables comme 'total_orders', 'total_spent', et 'max_delivery_delay_days' présentent des valeurs extrêmes. Ces outliers peuvent être légitimes dans le contexte d'un site e-commerce (par exemple, des clients très fidèles ou des commandes très importantes), mais il faudra les prendre en compte lors de la modélisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf96878",
   "metadata": {},
   "source": [
    "## 4. Analyse des variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc525e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes catégorielles\n",
    "categorical_columns = df.select_dtypes(exclude=['number']).columns\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(categorical_columns)\n",
    "\n",
    "# Affichage des valeurs uniques pour chaque variable catégorielle\n",
    "for col in categorical_columns:\n",
    "    # Seulement si ce n'est pas customer_unique_id\n",
    "    if col == 'customer_unique_id':\n",
    "        continue\n",
    "    print(f\"\\nValeurs uniques dans {col}:\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d28581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La colonne \"last_order_status\" ne contient qu'une seule valeur à l'exception de 6 individus, on la supprime\n",
    "df = df.drop(columns=['last_order_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98fe408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La colonne \"last_payment_type\" contient une majorité de \"credit_card\". Nous allons utiliser 2 valeurs pour cette colonne, credit_card et other\n",
    "df['last_payment_type'] = df['last_payment_type'].apply(lambda x: 'credit_card' if x == 'credit_card' else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f31e9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes catégorielles sans customer_unique_id\n",
    "categorical_columns = categorical_columns.drop(['customer_unique_id', 'last_order_status'])\n",
    "\n",
    "# # Visualisation de la distribution de la variable catégorielle \"last_payment_type\"\n",
    "sns.countplot(y=df['last_payment_type'])\n",
    "plt.title('Distribution de last_payment_type')\n",
    "plt.xlabel('Nombre d\\'occurrences')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(len(categorical_columns), 1, figsize=(12, 6*len(categorical_columns)))\n",
    "\n",
    "# for idx, col in enumerate(categorical_columns):\n",
    "#     sns.countplot(y=df[col], ax=axes[idx])\n",
    "#     axes[idx].set_title(f'Distribution de {col}')\n",
    "#     axes[idx].set_xlabel('Nombre d\\'occurrences')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ea970",
   "metadata": {},
   "source": [
    "## 5. Analyse des corrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f541ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corrélation\n",
    "correlation_matrix = df[numeric_columns].corr()\n",
    "\n",
    "# Visualisation de la matrice de corrélation\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Matrice de corrélation des variables numériques')\n",
    "plt.show()\n",
    "\n",
    "# Sauvegarde de la matrice de corrélation\n",
    "correlation_matrix.to_csv('data/correlation_matrix.csv')\n",
    "print(\"La matrice de corrélation a été sauvegardée dans 'data/correlation_matrix.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04116d8f",
   "metadata": {},
   "source": [
    "### Analyse des corrélations\n",
    "\n",
    "On peut observer quelques corrélations intéressantes :\n",
    "1. Une forte corrélation positive entre 'total_orders' et 'total_spent', ce qui est logique.\n",
    "2. Une corrélation modérée entre 'avg_delivery_time_days' et 'avg_delivery_delay_days', ce qui suggère que les retards de livraison contribuent significativement au temps de livraison total.\n",
    "3. Une faible corrélation négative entre 'avg_review_score' et 'avg_delivery_delay_days', indiquant que les retards de livraison peuvent légèrement impacter la satisfaction client.\n",
    "\n",
    "Ces corrélations seront importantes à considérer lors de la phase de modélisation pour éviter la multicolinéarité et pour choisir les variables les plus pertinentes pour la segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2295e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca9272",
   "metadata": {},
   "source": [
    "# 9. Conclusion et prochaines étapes\n",
    "\n",
    "\"\"\"\n",
    "### Résumé de l'analyse exploratoire\n",
    "\n",
    "1. **Données initiales** : Nous avons analysé un jeu de données de 97078 clients d'un site e-commerce, comprenant diverses variables comportementales et transactionnelles.\n",
    "\n",
    "2. **Préparation des données** :\n",
    "   - Traitement des valeurs manquantes\n",
    "   - Suppression des outliers sur les variables clés\n",
    "   - Simplification des variables catégorielles\n",
    "   - Feature engineering pour créer des variables plus pertinentes\n",
    "\n",
    "3. **Variables importantes** :\n",
    "   - La majorité des clients ont effectué une seule commande\n",
    "   - Les délais de livraison varient considérablement\n",
    "   - La satisfaction client (review score) est généralement élevée\n",
    "   - Les modes de paiement sont dominés par la carte de crédit\n",
    "\n",
    "4. **Corrélations notables** :\n",
    "   - Lien entre temps de livraison et satisfaction client\n",
    "   - Corrélation entre méthode de paiement et montant dépensé\n",
    "   - Lien entre fréquence d'achat et fidélité\n",
    "\n",
    "### Prochaines étapes\n",
    "\n",
    "1. **Modélisation** :\n",
    "   - Standardisation des variables numériques\n",
    "   - Application d'algorithmes de clustering (K-means, DBSCAN)\n",
    "   - Analyse RFM (Récence, Fréquence, Montant)\n",
    "\n",
    "2. **Segmentation** :\n",
    "   - Détermination du nombre optimal de segments\n",
    "   - Caractérisation des segments de clients\n",
    "   - Validation de la pertinence business des segments\n",
    "\n",
    "3. **Exploitation** :\n",
    "   - Développement de stratégies marketing personnalisées par segment\n",
    "   - Mise en place d'un suivi de l'évolution des segments dans le temps\n",
    "   - Optimisation des parcours client en fonction des segments\n",
    "\n",
    "Le dataset nettoyé et augmenté servira de base solide pour la phase de segmentation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Préparation du dataset final\n",
    "# Vérifions qu'il n'y a plus de valeurs manquantes\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Vérification des valeurs manquantes dans le dataset:\")\n",
    "display(missing_values[missing_values > 0])\n",
    "\n",
    "# Si nécessaire, supprimons les observations avec des valeurs manquantes\n",
    "if missing_values.sum() > 0:\n",
    "    df = df.dropna()\n",
    "    print(f\"Après suppression des valeurs manquantes, nous avons {df.shape[0]} observations.\")\n",
    "\n",
    "# Simplifions la colonne \"last_payment_type\" en catégories plus pertinentes\n",
    "df['last_payment_type'] = df['last_payment_type'].apply(lambda x: 'credit_card' if x == 'credit_card' else 'other')\n",
    "\n",
    "# Création d'une nouvelle colonne pour préserver les données originales\n",
    "df['payment_type_binary'] = df['last_payment_type'].map({\n",
    "    'credit_card': 'credit_card'\n",
    "}).fillna('other')\n",
    "\n",
    "# Affichage de la distribution des types de paiement\n",
    "print(\"Distribution des types de paiement :\")\n",
    "display(df['payment_type_binary'].value_counts(normalize=True))\n",
    "\n",
    "# Supprimons les colonnes inutiles ou redondantes\n",
    "columns_to_drop = ['total_orders', 'total_spent']\n",
    "\n",
    "# Vérifions si les colonnes avg_delivery_delay_days et max_delivery_delay_days sont identiques\n",
    "if 'avg_delivery_delay_days' in df.columns and 'max_delivery_delay_days' in df.columns:\n",
    "    similarity = (df['avg_delivery_delay_days'] == df['max_delivery_delay_days']).mean()\n",
    "    print(f\"Les colonnes avg_delivery_delay_days et max_delivery_delay_days sont identiques à {similarity*100:.2f}%\")\n",
    "    if similarity > 0.99:  # Si plus de 99% similaires\n",
    "        columns_to_drop.append('avg_delivery_delay_days')\n",
    "        print(\"La colonne avg_delivery_delay_days sera supprimée car presque identique à max_delivery_delay_days.\")\n",
    "    else:\n",
    "        print(\"Les deux colonnes sont conservées car elles contiennent des informations différentes.\")\n",
    "\n",
    "# Suppression des colonnes inutiles\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "print(f\"\\nLe dataset final contient {df.shape[0]} observations et {df.shape[1]} variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffd8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération du fichier csv clean pour les modèles de machine learning\n",
    "df.to_csv('data/clean.csv', index=False)\n",
    "print(\"Le dataset nettoyé a été sauvegardé dans 'data/clean.csv'\")\n",
    "\n",
    "# Affichage d'un échantillon du dataset final\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2618ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_summary(df):\n",
    "    print(\"\\nRésumé du dataset final:\")\n",
    "    print(f\"- Nombre d'observations: {df.shape[0]:,}\")\n",
    "    print(f\"- Nombre de variables: {df.shape[1]}\")\n",
    "    print(\"\\nTypes des variables:\")\n",
    "    display(df.dtypes)\n",
    "    print(\"\\nAperçu des premières lignes:\")\n",
    "    display(df.head())\n",
    "\n",
    "print_dataset_summary(df)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.16.7"
   }
  },
  "kernelspec": {
   "display_name": "oc-p4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
